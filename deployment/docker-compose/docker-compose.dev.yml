services:
  pipeshub-ai:
    image: pipeshub-ai:latest
    container_name: pipeshub-ai
    restart: always
    build:
      context: ../../
      dockerfile: Dockerfile
    ports:
      - "8091:8091"
      - "8088:8088"
      - "3000:3000"
      - "8000:8000"
    env_file:
      - ./.env
    depends_on:
      qdrant:
        condition: service_healthy
      kafka-1:
        condition: service_started
      redis:
        condition: service_started
      mongodb:
        condition: service_started
      etcd:
        condition: service_started
      arango:
        condition: service_started
    volumes:
      - pipeshub_data:/data/pipeshub
      - pipeshub_root_local:/root/.local

  mongodb:
    image: mongo:8.0.6
    container_name: mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - mongodb_data:/data/db

  redis:
    image: redis:bookworm
    container_name: redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  arango:
    image: arangodb:3.12.4
    container_name: arango
    restart: always
    ports:
      - "8529:8529"
    environment:
      ARANGO_ROOT_PASSWORD: your_password
    volumes:
      - arango_data:/var/lib/arangodb3

  etcd:
    image: quay.io/coreos/etcd:v3.5.17
    container_name: etcd-server
    restart: always
    ports:
      - "2379:2379"
      - "2380:2380"
    command: >
      etcd
      --name etcd-node
      --data-dir /etcd-data
      --listen-client-urls http://0.0.0.0:2379
      --advertise-client-urls http://0.0.0.0:2379
      --listen-peer-urls http://0.0.0.0:2380
      --initial-advertise-peer-urls http://0.0.0.0:2380
      --initial-cluster etcd-node=http://0.0.0.0:2380
    volumes:
      - etcd_data:/etcd-data

  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    restart: always
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data

  kafka-1:
    image: confluentinc/cp-kafka:7.9.0
    container_name: kafka-1
    restart: always
    depends_on:
      - zookeeper # Waits for ZK container to start
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ACCESS:PLAINTEXT # Define a single listener type

      KAFKA_LISTENERS: ACCESS://0.0.0.0:9092

      KAFKA_ADVERTISED_LISTENERS: ACCESS://kafka-1:9092

      KAFKA_INTER_BROKER_LISTENER_NAME: ACCESS
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CREATE_TOPICS: "record-events:1:1,entity-events:1:1,sync-events:1:1" # Example topics
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_NUM_NETWORK_THREADS: 3 # Default is 3
      KAFKA_NUM_IO_THREADS: 8 # Default is 8

    volumes:
      - kafka_data:/var/lib/kafka/data

  qdrant:
    image: qdrant/qdrant:v1.13.6
    container_name: qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_storage:/qdrant/storage
    ulimits:
      nofile:
        soft: 50000
        hard: 50000
    restart: always
    healthcheck:
      test:
        - CMD-SHELL
        - bash -c ':> /dev/tcp/127.0.0.1/6333' || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  mongodb_data:
    driver: local
  redis_data:
    driver: local
  arango_data:
    driver: local
  etcd_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local
  qdrant_storage:
    driver: local
  pipeshub_data:
    driver: local
  pipeshub_root_local:
    driver: local
